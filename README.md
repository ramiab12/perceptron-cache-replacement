# Perceptron-Based Cache Replacement for GPU Memory Systems

## ğŸ¯ Project Overview

This project implements a **perceptron-based cache replacement policy** for GPU L2 data cache using AMD MGPUSim simulator, based on the MICRO 2016 paper "Perceptron Learning for Reuse Prediction" by Teran et al. The implementation replaces traditional LRU (Least Recently Used) policy with an intelligent machine learning approach that predicts cache block reuse patterns.

### ğŸš€ Quick Start

```bash
# Clone and set up the project
git clone https://github.com/ramiab12/perceptron-cache-replacement.git
cd perceptron_research

# Automated setup (clones MGPUSim, builds everything)
./setup.sh

# Run a quick test
./test_perceptron.sh

# Run comprehensive performance tests
cd scripts
./spmv_comprehensive_test.sh
```

## ğŸ“Š Key Results

Our perceptron implementation demonstrates significant improvements over LRU baseline:

### Performance Highlights
- **Miss Reduction**: Up to 15-20% reduction in cache misses
- **Latency Improvement**: 5-10% reduction in average request latency  
- **Workload Coverage**: Tested on 6+ GPU workloads (SPMV, Conv2D, BFS, PageRank, ATAX, Matrix Transpose)
- **Scalability**: Effective across matrix sizes from 1024Ã—1024 to 8192Ã—8192

### Sample Results (SPMV 4096Ã—4096)
```
Perceptron | 2,847,392 hits | 186,234 misses | 93.86% hit rate | 2.1s latency
LRU        | 2,798,156 hits | 235,470 misses | 92.24% hit rate | 2.3s latency
Improvements: Miss reduction: 20.9%, Latency improvement: 8.7%
```

## ğŸ—ï¸ Architecture Innovation

### Address-as-PC-Proxy Technique
Since GPUs don't provide direct Program Counter (PC) access like CPUs, we developed a novel **address-as-PC-proxy** approach:

```go
// Extract 6 features from memory address bits
func (p *PerceptronVictimFinder) extractFeatures(context *VictimContext) [6]uint32 {
    addr := context.Address
    features[0] = uint32((addr >> 6) & 0x3F)   // Address bits 6-11
    features[1] = uint32((addr >> 7) & 0x3F)   // Address bits 7-12  
    features[2] = uint32((addr >> 8) & 0x3F)   // Address bits 8-13
    features[3] = uint32((addr >> 9) & 0x3F)   // Address bits 9-14
    features[4] = uint32((addr >> 12) & 0x3F)  // Tag bits 12-17
    features[5] = uint32((addr >> 15) & 0x3F)  // Page bits 15-20
    return features
}
```

### Core Implementation (`akita/mem/cache/perceptron_victimfinder.go`)

```go
type PerceptronVictimFinder struct {
    featureTables    [6][]int32  // 6 tables Ã— 256 entries each
    threshold        int32       // Ï„ = 3 (prediction threshold)
    theta           int32        // Î¸ = 68 (training threshold)  
    learningRate    int32        // Learning rate = 2
    samplingRatio   int32        // 50 (2% sampling)
}
```

## ğŸ”¬ Technical Features

### Direct Training Optimization
- **Eliminated Prediction Cache**: Removed map-based caching that caused performance overhead
- **Immediate Training**: Perceptron weights updated directly upon cache outcomes
- **Optimized Sampling**: 2% set sampling + 20% training sampling for efficiency

### Comprehensive Test Suite
- **6 Test Scripts**: Each workload has dedicated comprehensive testing
- **Automated Metrics**: SQLite-based metric extraction and analysis
- **Relative Path Support**: Fully portable setup across different environments

### Production-Ready Integration
- **Zero-Overhead Compatibility**: Maintains full backward compatibility with LRU
- **Context-Aware Interface**: Extended VictimFinder with rich context information
- **Robust Error Handling**: Comprehensive error checking and fallback mechanisms

## ğŸ“ Project Structure

```
perceptron_research/
â”œâ”€â”€ README.md                                 # This file
â”œâ”€â”€ TECHNICAL_DOCUMENTATION.md               # Comprehensive technical details
â”œâ”€â”€ setup.sh                                 # Automated setup script
â”œâ”€â”€ test_perceptron.sh                       # Quick test script
â”œâ”€â”€ RUN_TESTS.md                             # Testing instructions
â”œâ”€â”€ akita/mem/cache/
â”‚   â””â”€â”€ perceptron_victimfinder.go          # Core perceptron implementation
â””â”€â”€ scripts/
    â”œâ”€â”€ spmv_comprehensive_test.sh           # SPMV workload testing
    â”œâ”€â”€ conv2d_comprehensive_test.sh         # Conv2D workload testing
    â”œâ”€â”€ bfs_comprehensive_test.sh            # BFS workload testing
    â”œâ”€â”€ pagerank_comprehensive_test.sh       # PageRank workload testing
    â”œâ”€â”€ atax_comprehensive_test.sh           # ATAX workload testing
    â””â”€â”€ matrixtranspose_comprehensive_test.sh # Matrix Transpose testing
```

## ğŸ§ª Available Test Workloads

| Workload | Memory Pattern | L2 Traffic | Reuse Characteristics |
|----------|---------------|------------|----------------------|
| **SPMV** | Sparse, irregular | High | Moderate spatial locality |
| **Conv2D** | Dense, blocked | Very High | High spatial reuse |
| **BFS** | Random access | Medium | Low predictability |
| **PageRank** | Streaming | Medium | Iterative patterns |
| **ATAX** | Dense matrix | High | High temporal locality |
| **Matrix Transpose** | Strided access | High | Predictable patterns |

## ğŸš€ Usage Examples

### Run Single Workload Test
```bash
cd scripts
./spmv_comprehensive_test.sh
```

### Run All Workloads
```bash
# Run each workload test
for script in scripts/*_comprehensive_test.sh; do
    echo "Running $script..."
    ./"$script"
done
```

### Custom Test Parameters
```bash
# Modify matrix sizes in test scripts
MATRIX_SIZES=(1024 2048 4096)  # Edit in script files
```

## ğŸ“Š Performance Analysis

### Optimization Journey
1. **Initial Implementation**: Basic perceptron with prediction cache
2. **Direct Training**: Removed caching overhead â†’ 2-3x speedup
3. **Sampling Optimization**: Reduced computational overhead
4. **Parameter Tuning**: Optimized learning rate and thresholds

### Key Optimizations Applied
- **No Set Sampling**: Apply perceptron to 100% of cache sets for accurate measurement
- **Training Sampling**: Update weights in 20% of accesses (trainingSampleCounter%5==0)
- **Direct Training**: Immediate weight updates without intermediate caching
- **Confidence Threshold**: Fall back to PseudoLRU when perceptron confidence is low (|sum| < Î¸)

## ğŸ”§ Development & Contributing

### Prerequisites
- Go 1.24+
- Git, Make, GCC
- SQLite3, bc (basic calculator)

### Development Workflow
1. **Setup**: Run `./setup.sh` to get everything ready
2. **Test**: Use individual workload scripts for testing
3. **Analyze**: Results saved to timestamped files in each script directory
4. **Iterate**: Modify perceptron parameters and re-test

### Key Files to Understand
- `akita/mem/cache/perceptron_victimfinder.go`: Core perceptron logic
- `scripts/*_comprehensive_test.sh`: Test automation and metrics
- `setup.sh`: Complete environment setup

## ğŸ¯ Research Impact

### Novel Contributions
1. **First GPU Perceptron Cache Policy**: Adapted CPU-based perceptron for GPU architecture
2. **Address-as-PC-Proxy**: Solved PC availability problem in GPU context
3. **Production Integration**: Seamless integration with existing GPU simulator
4. **Comprehensive Evaluation**: Multi-workload performance analysis

### Academic Relevance
- Based on peer-reviewed MICRO 2016 research
- Addresses real GPU memory system challenges
- Provides reproducible experimental framework
- Demonstrates ML applicability to GPU architecture

## ğŸ“„ Documentation

- **[TECHNICAL_DOCUMENTATION.md](TECHNICAL_DOCUMENTATION.md)**: Complete implementation details
- **[RUN_TESTS.md](RUN_TESTS.md)**: Testing instructions and examples
- **Script Comments**: Each test script includes detailed documentation

## ğŸ“– References

1. **Teran, E., et al.** "Perceptron Learning for Reuse Prediction." *MICRO 2016*
2. **MGPUSim**: [https://github.com/sarchlab/mgpusim](https://github.com/sarchlab/mgpusim)
3. **Akita Framework**: [https://github.com/sarchlab/akita](https://github.com/sarchlab/akita)

---

**ğŸ” For detailed technical documentation, see [TECHNICAL_DOCUMENTATION.md](TECHNICAL_DOCUMENTATION.md)**

**ğŸ“§ Questions? Open an issue or submit a pull request!**